{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit, col, udf, avg\n",
    "from pyspark.sql.types import IntegerType, FloatType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputDF = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load(\"datathon_tadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputDF.createOrReplaceTempView(\"input_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- day: timestamp (nullable = true)\n",
      " |-- gender: integer (nullable = true)\n",
      " |-- p_sessionActivity: integer (nullable = true)\n",
      " |-- p_AddToCart: integer (nullable = true)\n",
      " |-- p_trafficChannel: string (nullable = true)\n",
      " |-- p_sessionDuration: integer (nullable = true)\n",
      " |-- p_pageViews: integer (nullable = true)\n",
      " |-- daysToCheckin: string (nullable = true)\n",
      " |-- osType: integer (nullable = true)\n",
      " |-- osTypeName: string (nullable = true)\n",
      " |-- daysFromPreviousVisit: integer (nullable = true)\n",
      " |-- p_TotalPrice: string (nullable = true)\n",
      " |-- isExclusiveMember: integer (nullable = true)\n",
      " |-- loggedIn: integer (nullable = true)\n",
      " |-- p_MapInteraction: integer (nullable = true)\n",
      " |-- BookingPurchase: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputDF.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inputDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- gender: integer (nullable = true)\n",
      " |-- p_sessionActivity: integer (nullable = true)\n",
      " |-- p_AddToCart: integer (nullable = true)\n",
      " |-- p_trafficChannel: string (nullable = true)\n",
      " |-- p_sessionDuration: integer (nullable = true)\n",
      " |-- p_pageViews: integer (nullable = true)\n",
      " |-- daysToCheckin: string (nullable = true)\n",
      " |-- osType: integer (nullable = true)\n",
      " |-- daysFromPreviousVisit: integer (nullable = true)\n",
      " |-- p_TotalPrice: string (nullable = true)\n",
      " |-- isExclusiveMember: integer (nullable = true)\n",
      " |-- loggedIn: integer (nullable = true)\n",
      " |-- p_MapInteraction: integer (nullable = true)\n",
      " |-- BookingPurchase: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "selectDF = inputDF.select(\"user_id\", \"gender\", \"p_sessionActivity\", \"p_AddToCart\", \"p_trafficChannel\", \"p_sessionDuration\", \"p_pageViews\", \"daysToCheckin\", \"osType\", \"daysFromPreviousVisit\", \"p_TotalPrice\", \"isExclusiveMember\", \"loggedIn\", \"p_MapInteraction\", \"BookingPurchase\").dropna()\n",
    "selectDF.printSchema()\n",
    "# inputDF.filter(inputDF[\"daysToCheckin\"] != \"NA\").count()\n",
    "# inputDF.select(\"user_id\").distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avg_price = float(selectDF.select(avg(\"p_TotalPrice\")).take(1)[0][0])\n",
    "avg_checkin_days = float(selectDF.select(avg(\"daysToCheckin\")).take(1)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1323.226778024252 68.29791432633138\n"
     ]
    }
   ],
   "source": [
    "print(avg_price, avg_checkin_days)\n",
    "\n",
    "# UDF to filter and replace value\n",
    "def filterNA(cell_val, check_val, replace_val):\n",
    "    print(cell_val)\n",
    "    if (cell_val == check_val):\n",
    "        return replace_val\n",
    "    else:\n",
    "        return float(cell_val)\n",
    "\n",
    "filter_na_df = udf(filterNA, FloatType())\n",
    "cleanedDF = selectDF \\\n",
    ".withColumn(\"cleaned_daysToCheckin\", filter_na_df(\"daysToCheckin\", lit(\"NA\"), lit(avg_checkin_days))) \\\n",
    ".withColumn(\"cleaned_totalPrice\", filter_na_df(\"p_TotalPrice\", lit(\"NA\"), lit(avg_price))) \\\n",
    ".drop(\"daysToCheckin\", \"p_TotalPrice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanedDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|daysToCheckin|\n",
      "+-------------+\n",
      "|          296|\n",
      "|          125|\n",
      "|            7|\n",
      "|           51|\n",
      "|          124|\n",
      "|          447|\n",
      "|          307|\n",
      "|          169|\n",
      "|          205|\n",
      "|          544|\n",
      "|          272|\n",
      "|           15|\n",
      "|           54|\n",
      "|          232|\n",
      "|          234|\n",
      "|          282|\n",
      "|          383|\n",
      "|          155|\n",
      "|          154|\n",
      "|          132|\n",
      "|          317|\n",
      "|          200|\n",
      "|          388|\n",
      "|          495|\n",
      "|           11|\n",
      "|          101|\n",
      "|          279|\n",
      "|          415|\n",
      "|          433|\n",
      "|          138|\n",
      "|          323|\n",
      "|          351|\n",
      "|          361|\n",
      "|          387|\n",
      "|           29|\n",
      "|           69|\n",
      "|          309|\n",
      "|           42|\n",
      "|          112|\n",
      "|           73|\n",
      "|           87|\n",
      "|          468|\n",
      "|           64|\n",
      "|          308|\n",
      "|          348|\n",
      "|          356|\n",
      "|            3|\n",
      "|           30|\n",
      "|          113|\n",
      "|          432|\n",
      "|           34|\n",
      "|          133|\n",
      "|          287|\n",
      "|          365|\n",
      "|          389|\n",
      "|          162|\n",
      "|           59|\n",
      "|          139|\n",
      "|          146|\n",
      "|          310|\n",
      "|          250|\n",
      "|          352|\n",
      "|          379|\n",
      "|            8|\n",
      "|          160|\n",
      "|          258|\n",
      "|           22|\n",
      "|          203|\n",
      "|           28|\n",
      "|          184|\n",
      "|          199|\n",
      "|          343|\n",
      "|           85|\n",
      "|           35|\n",
      "|           16|\n",
      "|           52|\n",
      "|          251|\n",
      "|          171|\n",
      "|          183|\n",
      "|           NA|\n",
      "|            0|\n",
      "|          187|\n",
      "|          441|\n",
      "|           71|\n",
      "|           98|\n",
      "|          188|\n",
      "|          276|\n",
      "|          298|\n",
      "|          528|\n",
      "|           47|\n",
      "|          223|\n",
      "|          195|\n",
      "|           99|\n",
      "|          110|\n",
      "|          107|\n",
      "|          372|\n",
      "|          390|\n",
      "|          214|\n",
      "|          267|\n",
      "|          179|\n",
      "|          284|\n",
      "|          408|\n",
      "|          248|\n",
      "|           96|\n",
      "|          202|\n",
      "|          327|\n",
      "|          221|\n",
      "|          320|\n",
      "|           43|\n",
      "|          300|\n",
      "|            5|\n",
      "|          273|\n",
      "|          401|\n",
      "|          163|\n",
      "|           31|\n",
      "|          100|\n",
      "|           18|\n",
      "|          359|\n",
      "|           70|\n",
      "|          476|\n",
      "|          206|\n",
      "|          174|\n",
      "|          168|\n",
      "|          302|\n",
      "|          453|\n",
      "|          224|\n",
      "|          364|\n",
      "|          505|\n",
      "|           61|\n",
      "|          218|\n",
      "|           27|\n",
      "|           75|\n",
      "|          274|\n",
      "|          166|\n",
      "|          219|\n",
      "|          126|\n",
      "|          131|\n",
      "|           17|\n",
      "|          140|\n",
      "|           26|\n",
      "|          227|\n",
      "|          286|\n",
      "|          120|\n",
      "|          326|\n",
      "|           46|\n",
      "|          268|\n",
      "|          130|\n",
      "|          374|\n",
      "|          375|\n",
      "|          147|\n",
      "|          164|\n",
      "|          207|\n",
      "|          381|\n",
      "|           78|\n",
      "|          208|\n",
      "|          328|\n",
      "|           77|\n",
      "|           89|\n",
      "|          228|\n",
      "|          525|\n",
      "|          136|\n",
      "|          198|\n",
      "|          290|\n",
      "|            6|\n",
      "|          118|\n",
      "|          257|\n",
      "|          385|\n",
      "|          185|\n",
      "|          341|\n",
      "|          256|\n",
      "|          230|\n",
      "|          329|\n",
      "|          201|\n",
      "|          177|\n",
      "|          344|\n",
      "|           60|\n",
      "|           68|\n",
      "|           90|\n",
      "|          104|\n",
      "|          244|\n",
      "|          229|\n",
      "|          246|\n",
      "|          194|\n",
      "|           19|\n",
      "|          354|\n",
      "|          335|\n",
      "|          347|\n",
      "|           23|\n",
      "|          128|\n",
      "|          280|\n",
      "|           41|\n",
      "|          102|\n",
      "|           55|\n",
      "|          345|\n",
      "|          238|\n",
      "|          319|\n",
      "|          111|\n",
      "|          349|\n",
      "|          263|\n",
      "|          220|\n",
      "|          197|\n",
      "|          722|\n",
      "|          436|\n",
      "|          167|\n",
      "|           93|\n",
      "|           95|\n",
      "|           40|\n",
      "|          103|\n",
      "|           38|\n",
      "|          369|\n",
      "|          376|\n",
      "|           25|\n",
      "|          189|\n",
      "|          271|\n",
      "|          270|\n",
      "|          233|\n",
      "|          297|\n",
      "|          292|\n",
      "|          135|\n",
      "|           44|\n",
      "|          156|\n",
      "|          190|\n",
      "|          288|\n",
      "|          303|\n",
      "|          338|\n",
      "|          144|\n",
      "|          176|\n",
      "|           82|\n",
      "|          115|\n",
      "|          241|\n",
      "|          193|\n",
      "|          283|\n",
      "|           53|\n",
      "|          245|\n",
      "|          285|\n",
      "|           92|\n",
      "|          231|\n",
      "|          398|\n",
      "|          122|\n",
      "|          293|\n",
      "|          294|\n",
      "|          108|\n",
      "|          247|\n",
      "|          117|\n",
      "|          414|\n",
      "|           86|\n",
      "|           58|\n",
      "|          261|\n",
      "|          281|\n",
      "|          360|\n",
      "|          204|\n",
      "|          363|\n",
      "|          399|\n",
      "|           81|\n",
      "|          114|\n",
      "|           33|\n",
      "|          242|\n",
      "|          350|\n",
      "|          366|\n",
      "|          213|\n",
      "|          291|\n",
      "|          536|\n",
      "|          150|\n",
      "|          269|\n",
      "|          277|\n",
      "|          526|\n",
      "|          170|\n",
      "|          382|\n",
      "|          178|\n",
      "|           48|\n",
      "|          153|\n",
      "|          259|\n",
      "|          217|\n",
      "|          148|\n",
      "|          180|\n",
      "|          240|\n",
      "|          141|\n",
      "|          243|\n",
      "|          173|\n",
      "|          515|\n",
      "|           97|\n",
      "|          159|\n",
      "|          209|\n",
      "|          239|\n",
      "|          377|\n",
      "|          316|\n",
      "|          304|\n",
      "|          158|\n",
      "|           67|\n",
      "|          106|\n",
      "|          402|\n",
      "|           84|\n",
      "|          236|\n",
      "|          266|\n",
      "|          143|\n",
      "|          322|\n",
      "|           79|\n",
      "|          494|\n",
      "|           24|\n",
      "|            9|\n",
      "|          313|\n",
      "|          336|\n",
      "|          212|\n",
      "|          346|\n",
      "|           32|\n",
      "|          116|\n",
      "|          186|\n",
      "|          152|\n",
      "|          299|\n",
      "|          314|\n",
      "|          513|\n",
      "|           88|\n",
      "|          134|\n",
      "|          358|\n",
      "|            1|\n",
      "|          149|\n",
      "|          318|\n",
      "|          105|\n",
      "|          237|\n",
      "|          289|\n",
      "|           20|\n",
      "|          325|\n",
      "|          305|\n",
      "|          342|\n",
      "|          142|\n",
      "|          357|\n",
      "|           56|\n",
      "|          127|\n",
      "|          485|\n",
      "|          295|\n",
      "|           36|\n",
      "|          211|\n",
      "|          409|\n",
      "|           10|\n",
      "|          420|\n",
      "|           37|\n",
      "|          165|\n",
      "|          371|\n",
      "|          386|\n",
      "|           49|\n",
      "|          255|\n",
      "|          275|\n",
      "|          253|\n",
      "|          222|\n",
      "|          362|\n",
      "|          172|\n",
      "|          575|\n",
      "|           63|\n",
      "|          181|\n",
      "|          306|\n",
      "|           65|\n",
      "|          312|\n",
      "|          225|\n",
      "|          235|\n",
      "|          265|\n",
      "|          331|\n",
      "|            4|\n",
      "|          121|\n",
      "|           39|\n",
      "|          252|\n",
      "|          210|\n",
      "|          315|\n",
      "|          411|\n",
      "|           62|\n",
      "|          704|\n",
      "|           12|\n",
      "|          339|\n",
      "|           83|\n",
      "|          417|\n",
      "|          333|\n",
      "|          123|\n",
      "|          109|\n",
      "|          215|\n",
      "|          396|\n",
      "|          249|\n",
      "|           13|\n",
      "|          191|\n",
      "|          157|\n",
      "|          260|\n",
      "|           14|\n",
      "|           21|\n",
      "|          182|\n",
      "|           66|\n",
      "|          264|\n",
      "|           94|\n",
      "|          175|\n",
      "|           91|\n",
      "|           72|\n",
      "|          137|\n",
      "|           74|\n",
      "|          161|\n",
      "|          151|\n",
      "|          355|\n",
      "|          489|\n",
      "|          321|\n",
      "|          367|\n",
      "|          353|\n",
      "|          262|\n",
      "|          129|\n",
      "|          368|\n",
      "|           76|\n",
      "|          378|\n",
      "|            2|\n",
      "|          278|\n",
      "|          196|\n",
      "|          254|\n",
      "|          370|\n",
      "|          192|\n",
      "|          311|\n",
      "|           80|\n",
      "|          226|\n",
      "|          340|\n",
      "|          324|\n",
      "|          504|\n",
      "|          301|\n",
      "|          532|\n",
      "|           50|\n",
      "|          145|\n",
      "|          330|\n",
      "|           57|\n",
      "|           45|\n",
      "|          332|\n",
      "|          216|\n",
      "|          522|\n",
      "|          119|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputDF.select(col(\"daysToCheckin\")).distinct().show(inputDF.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|p_trafficChannel|\n",
      "+----------------+\n",
      "|               O|\n",
      "|               O|\n",
      "|               O|\n",
      "|               O|\n",
      "|               O|\n",
      "|               A|\n",
      "|               A|\n",
      "|               O|\n",
      "|               H|\n",
      "|               O|\n",
      "|               O|\n",
      "|               O|\n",
      "|               O|\n",
      "|               O|\n",
      "|               O|\n",
      "|               H|\n",
      "|               A|\n",
      "|               O|\n",
      "|               O|\n",
      "|               A|\n",
      "+----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------+------+-----------------+-----------+-----------------+-----------+------+---------------------+-----------------+--------+----------------+---------------+---------------------+------------------+-------------------+\n",
      "|user_id|gender|p_sessionActivity|p_AddToCart|p_sessionDuration|p_pageViews|osType|daysFromPreviousVisit|isExclusiveMember|loggedIn|p_MapInteraction|BookingPurchase|cleaned_daysToCheckin|cleaned_totalPrice|trafficChannelIndex|\n",
      "+-------+------+-----------------+-----------+-----------------+-----------+------+---------------------+-----------------+--------+----------------+---------------+---------------------+------------------+-------------------+\n",
      "|      1|     1|                1|          0|               73|          1|     8|                   10|                0|       0|               0|              0|             68.29791|         1323.2268|                0.0|\n",
      "|      2|     1|                0|          0|              234|          4|     7|                   42|                0|       0|               0|              0|             68.29791|         1323.2268|                0.0|\n",
      "|      3|     0|               53|          0|              341|          5|     7|                    0|                1|       1|               0|              1|                123.0|             166.0|                0.0|\n",
      "|      4|     1|                0|          0|              778|          1|     7|                    1|                0|       0|               0|              0|             68.29791|         1323.2268|                0.0|\n",
      "|      5|     1|                0|          0|               34|          1|     7|                    2|                0|       0|               0|              0|             68.29791|         1323.2268|                0.0|\n",
      "|      6|     1|                1|          0|              375|          1|     7|                    2|                0|       0|               0|              1|             68.29791|         1323.2268|                1.0|\n",
      "|      7|     0|               39|          0|              825|         20|     7|                    0|                0|       0|               0|              0|             68.29791|         1323.2268|                1.0|\n",
      "|      8|     0|                0|          0|              320|          6|     8|                    7|                0|       0|               0|              1|             68.29791|         1323.2268|                0.0|\n",
      "|      9|     1|                0|          0|                2|          1|    10|                   14|                0|       0|               0|              1|             68.29791|         1323.2268|                2.0|\n",
      "|     10|     0|               64|          1|            35113|         96|     7|                    3|                1|       1|               0|              0|                135.0|            1340.0|                0.0|\n",
      "|     11|     1|                0|          0|              242|          8|     7|                   15|                0|       0|               0|              0|             68.29791|         1323.2268|                0.0|\n",
      "|     12|     0|                0|          0|                1|          1|     7|                   13|                0|       0|               0|              0|             68.29791|         1323.2268|                0.0|\n",
      "|     13|     0|               14|          0|              853|         15|     7|                    1|                0|       0|               0|              0|             68.29791|         1323.2268|                0.0|\n",
      "|     14|     1|                0|          0|              106|          3|    13|                    1|                0|       0|               0|              0|             68.29791|         1323.2268|                0.0|\n",
      "|     15|     1|                0|          0|                7|          1|     8|                    8|                0|       0|               0|              0|             68.29791|         1323.2268|                0.0|\n",
      "|     16|     1|                0|          0|              178|          3|     7|                    6|                0|       1|               0|              1|                 24.0|         1323.2268|                2.0|\n",
      "|     17|     0|                5|          0|             2375|          1|    10|                   48|                0|       0|               0|              1|             68.29791|         1323.2268|                1.0|\n",
      "|     18|     0|                0|          0|               18|          1|     8|                    2|                0|       0|               0|              1|             68.29791|         1323.2268|                0.0|\n",
      "|     19|     0|                8|          0|             6853|          7|     7|                    3|                1|       0|               0|              1|             68.29791|         1323.2268|                0.0|\n",
      "|     20|     0|                1|          0|              134|          1|    10|                    3|                0|       0|               0|              0|             68.29791|         1323.2268|                1.0|\n",
      "+-------+------+-----------------+-----------+-----------------+-----------+------+---------------------+-----------------+--------+----------------+---------------+---------------------+------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "cleanedDF.select(\"p_trafficChannel\").show()\n",
    "indexer = StringIndexer(inputCol=\"p_trafficChannel\", outputCol=\"trafficChannelIndex\")\n",
    "indexedDF = indexer.fit(cleanedDF).transform(cleanedDF).drop(\"p_trafficChannel\")\n",
    "indexedDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- gender: integer (nullable = true)\n",
      " |-- p_sessionActivity: integer (nullable = true)\n",
      " |-- p_AddToCart: integer (nullable = true)\n",
      " |-- p_sessionDuration: integer (nullable = true)\n",
      " |-- p_pageViews: integer (nullable = true)\n",
      " |-- osType: integer (nullable = true)\n",
      " |-- daysFromPreviousVisit: integer (nullable = true)\n",
      " |-- isExclusiveMember: integer (nullable = true)\n",
      " |-- loggedIn: integer (nullable = true)\n",
      " |-- p_MapInteraction: integer (nullable = true)\n",
      " |-- BookingPurchase: integer (nullable = true)\n",
      " |-- cleaned_daysToCheckin: float (nullable = true)\n",
      " |-- cleaned_totalPrice: float (nullable = true)\n",
      " |-- trafficChannelIndex: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexedDF.count()\n",
    "indexedDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer\n",
    "\n",
    "encoder1 = OneHotEncoder(inputCol=\"trafficChannelIndex\", outputCol=\"trafficChannelVec\")\n",
    "encodedDF1 = encoder1.transform(indexedDF)\n",
    "encoder2 = OneHotEncoder(inputCol=\"osType\", outputCol=\"osTypeVec\")\n",
    "encodedDF2 = encoder2.transform(encodedDF1)\n",
    "# encodedDF2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|(30,[0,1,2,11,19,...|    0|\n",
      "|(30,[1,2,10,19,23...|    0|\n",
      "|(30,[0,1,2,10,20,...|    1|\n",
      "|(30,[1,2,10,19,23...|    0|\n",
      "|(30,[1,2,10,19,23...|    0|\n",
      "|(30,[0,1,2,10,19,...|    1|\n",
      "|(30,[0,1,2,10,24,...|    0|\n",
      "|(30,[1,2,11,19,23...|    1|\n",
      "|(30,[1,2,13,19,25...|    1|\n",
      "|(30,[0,1,2,10,19,...|    0|\n",
      "|(30,[1,2,10,19,23...|    0|\n",
      "|(30,[1,2,10,19,23...|    0|\n",
      "|(30,[0,1,2,10,19,...|    0|\n",
      "|(30,[1,2,16,19,23...|    0|\n",
      "|(30,[1,2,11,19,23...|    0|\n",
      "|(30,[1,2,10,19,21...|    1|\n",
      "|(30,[0,1,2,13,19,...|    1|\n",
      "|(30,[1,2,11,19,23...|    1|\n",
      "|(30,[0,1,2,10,19,...|    1|\n",
      "|(30,[0,1,2,13,19,...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"p_sessionActivity\", \"p_sessionDuration\", \"p_pageViews\", \"osTypeVec\", \"daysFromPreviousVisit\", \"isExclusiveMember\", \"loggedIn\", \"p_MapInteraction\", \"trafficChannelVec\", \"cleaned_totalPrice\", \"cleaned_daysToCheckin\"],\n",
    "    outputCol=\"features\")\n",
    "\n",
    "featureDF = assembler.transform(encodedDF2).select(\"features\", col(\"BookingPurchase\").alias(\"label\"))\n",
    "featureDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X = featureDF.select(\"features\").rdd.map(lambda row: (row[0].toArray())).collect()\n",
    "#y = featureDF.select(\"label\").rdd.map(lambda row: (row[0])).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "presentDF = featureDF.filter(col(\"label\") == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "featureDF = featureDF.union(presentDF)\n",
    "# .union(presentDF).union(presentDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#input_X.shape\n",
    "df = featureDF.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#input_X = np.array(X)\n",
    "#output_y = np.array(y)\n",
    "np_mat = df.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1861360, 2)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = featureDF.toPandas()\n",
    "\n",
    "label_yes = df['label'] == 1\n",
    "df_yes = df[label_yes]\n",
    "df_oversampled = df.append([df_yes] * 4, ignore_index=True)\n",
    "df_oversampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ..., 1 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1861360, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "Y = np.array(df_oversampled['label'])\n",
    "print(Y)\n",
    "X = np.array(df_oversampled[df_oversampled.columns[:-1]])\n",
    "X.shape\n",
    "#dt = DecisionTreeClassifier(random_state=0)\n",
    "#dt.fit(X, Y)\n",
    "#scores = cross_val_score(dt, X, Y, cv=10)\n",
    "#scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_predict = clf.predict(X_test)\n",
    "accuracy_score(y_test, t_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized using L^1 norm\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Normalizer, StandardScaler\n",
    "\n",
    "# Normalize each Vector using $L^1$ norm.\n",
    "normalizer = Normalizer(inputCol=\"features\", outputCol=\"normFeatures\", p=2.0)\n",
    "normDF = normalizer.transform(featureDF)\n",
    "print(\"Normalized using L^1 norm\")\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"normFeatures\", outputCol=\"scaledFeatures\",\n",
    "                        withStd=True, withMean=False)\n",
    "\n",
    "# Compute summary statistics by fitting the StandardScaler\n",
    "scalerModel = scaler.fit(normDF)\n",
    "\n",
    "# Normalize each feature to have unit standard deviation.\n",
    "scaledDF = scalerModel.transform(normDF).select(col(\"scaledFeatures\").alias(\"features\"), \"label\")\n",
    "# scaledDF.show(truncate=False).map(lambda row: row.get[0].toArray(), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "\n",
    "train, test = scaledDF.randomSplit([0.9, 0.1], seed=12345)\n",
    "\n",
    "lr = LogisticRegression(maxIter=50)\n",
    "\n",
    "\n",
    "# We use a ParamGridBuilder to construct a grid of parameters to search over.\n",
    "# TrainValidationSplit will try all combinations of values and determine best model using\n",
    "# the evaluator.\n",
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(lr.regParam, [0.1, 0.3, 0.01]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.0, 0.01, 0.1, 0.5, 0.8, 1.0])\\\n",
    "    .build()\n",
    "\n",
    "# In this case the estimator is simply the linear regression.\n",
    "# A TrainValidationSplit requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.\n",
    "tvs = TrainValidationSplit(estimator=lr,\n",
    "                           estimatorParamMaps=paramGrid,\n",
    "                           evaluator=BinaryClassificationEvaluator(),\n",
    "                           # 80% of the data will be used for training, 20% for validation.\n",
    "                           trainRatio=0.7)\n",
    "\n",
    "# Run TrainValidationSplit, and choose the best set of parameters.\n",
    "model = tvs.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----------+\n",
      "|            features|label|prediction|\n",
      "+--------------------+-----+----------+\n",
      "|(30,[0,1,2,4,19,2...|    1|       1.0|\n",
      "|(30,[0,1,2,4,19,2...|    0|       1.0|\n",
      "|(30,[0,1,2,4,19,2...|    1|       1.0|\n",
      "|(30,[0,1,2,4,19,2...|    0|       1.0|\n",
      "|(30,[0,1,2,4,19,2...|    0|       1.0|\n",
      "|(30,[0,1,2,4,19,2...|    0|       1.0|\n",
      "|(30,[0,1,2,4,19,2...|    0|       1.0|\n",
      "|(30,[0,1,2,4,19,2...|    0|       1.0|\n",
      "|(30,[0,1,2,4,19,2...|    0|       1.0|\n",
      "|(30,[0,1,2,4,19,2...|    0|       1.0|\n",
      "|(30,[0,1,2,4,19,2...|    0|       1.0|\n",
      "|(30,[0,1,2,4,19,2...|    1|       1.0|\n",
      "|(30,[0,1,2,4,19,2...|    1|       1.0|\n",
      "|(30,[0,1,2,4,19,2...|    1|       1.0|\n",
      "|(30,[0,1,2,4,19,2...|    0|       1.0|\n",
      "|(30,[0,1,2,4,19,2...|    0|       1.0|\n",
      "|(30,[0,1,2,4,19,2...|    0|       1.0|\n",
      "|(30,[0,1,2,4,19,2...|    0|       1.0|\n",
      "|(30,[0,1,2,4,19,2...|    1|       1.0|\n",
      "|(30,[0,1,2,4,19,2...|    1|       1.0|\n",
      "+--------------------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test data. model is the model with combination of parameters\n",
    "# that performed best.\n",
    "tvresult = model.transform(test)\n",
    "tvresult.select(\"features\", \"label\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mapRow(row):\n",
    "    if (row[0] == int(row[1])): \n",
    "         return 1\n",
    "    else:\n",
    "         return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numCorrectPredictions = tvresult.select(\"label\", \"prediction\").rdd.map(lambda row: mapRow(row)).reduce(lambda a, b: a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "numCorrectPredictions\n",
    "accuracy = 1.0 * numCorrectPredictions / tvresult.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy: 0.5873891805491167\n"
     ]
    }
   ],
   "source": [
    "print(\"Test set accuracy: \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.7837440394811431\n"
     ]
    }
   ],
   "source": [
    "#Multi Layer perceptron\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Split the data into train and test\n",
    "splits = scaledDF.randomSplit([0.7, 0.3], 1234)\n",
    "train = splits[0]\n",
    "test = splits[1]\n",
    "\n",
    "# specify layers for the neural network:\n",
    "# input layer of size 4 (features), two intermediate of size 5 and 4\n",
    "# and output of size 3 (classes)\n",
    "layers = [30, 25, 20, 10, 7, 4, 2]\n",
    "\n",
    "# create the trainer and set its parameters\n",
    "trainer = MultilayerPerceptronClassifier(maxIter=100, layers=layers, blockSize=128, seed=1234)\n",
    "\n",
    "# train the model\n",
    "model = trainer.fit(train)\n",
    "\n",
    "# compute accuracy on the test set\n",
    "percResult = model.transform(test)\n",
    "predictionAndLabels = percResult.select(\"prediction\", \"label\")\n",
    "evaluator = MulticlassClassificationEvaluator(metricName=\"accuracy\")\n",
    "print(\"Test set accuracy = \" + str(evaluator.evaluate(predictionAndLabels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------------------+\n",
      "|prediction|label|            features|\n",
      "+----------+-----+--------------------+\n",
      "|       1.0|    0|(30,[0,1,2,11,19,...|\n",
      "|       1.0|    0|(30,[1,2,10,19,23...|\n",
      "|       1.0|    1|(30,[0,1,2,10,20,...|\n",
      "|       1.0|    0|(30,[1,2,10,19,23...|\n",
      "|       1.0|    0|(30,[1,2,10,19,23...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test Accuracy = 0.590388\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "#(trainingData, testData) = scaledDF.randomSplit([0.7, 0.3])\n",
    "trainingData = scaledDF\n",
    "testData = scaledDF\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=25)\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "rfmodel = rf.fit(trainingData)\n",
    "\n",
    "# Make predictions.\n",
    "rfpredictions = rfmodel.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "rfpredictions.select(\"prediction\", \"label\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(rfpredictions)\n",
    "print(\"Test Accuracy = %g\" % accuracy)\n",
    "\n",
    "# rfModel = rfmodel.stages[2]\n",
    "# print(rfModel)  # summary only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1753476"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfpredictions.filter(col(\"prediction\") == 1.0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|(30,[0,1,2,4,19,2...|    1|[9.34620323199338...|[0.37384812927973...|       1.0|\n",
      "|(30,[0,1,2,4,19,2...|    1|[9.21128345186936...|[0.36845133807477...|       1.0|\n",
      "|(30,[0,1,2,4,19,2...|    0|[9.13431756328675...|[0.36537270253147...|       1.0|\n",
      "|(30,[0,1,2,4,19,2...|    1|[9.17334883731972...|[0.36693395349278...|       1.0|\n",
      "|(30,[0,1,2,4,19,2...|    0|[9.46915528655994...|[0.37876621146239...|       1.0|\n",
      "|(30,[0,1,2,4,19,2...|    1|[9.35181320488357...|[0.37407252819534...|       1.0|\n",
      "|(30,[0,1,2,4,19,2...|    0|[9.51067735192804...|[0.38042709407712...|       1.0|\n",
      "|(30,[0,1,2,4,19,2...|    1|[9.72069373616058...|[0.38882774944642...|       1.0|\n",
      "|(30,[0,1,2,4,19,2...|    0|[9.87103413617538...|[0.39484136544701...|       1.0|\n",
      "|(30,[0,1,2,4,19,2...|    1|[9.87103413617538...|[0.39484136544701...|       1.0|\n",
      "|(30,[0,1,2,4,19,2...|    1|[9.43181468148586...|[0.37727258725943...|       1.0|\n",
      "|(30,[0,1,2,4,19,2...|    1|[9.75649451742838...|[0.39025978069713...|       1.0|\n",
      "|(30,[0,1,2,4,19,2...|    0|[9.65766046775768...|[0.38630641871030...|       1.0|\n",
      "|(30,[0,1,2,4,19,2...|    0|[9.84002266341209...|[0.39360090653648...|       1.0|\n",
      "|(30,[0,1,2,4,19,2...|    0|[9.77874666068905...|[0.39114986642756...|       1.0|\n",
      "|(30,[0,1,2,4,19,2...|    0|[9.84075117074278...|[0.39363004682971...|       1.0|\n",
      "|(30,[0,1,2,4,19,2...|    0|[9.32233045196551...|[0.37289321807862...|       1.0|\n",
      "|(30,[0,1,2,4,19,2...|    0|[8.90642584298675...|[0.35625703371947...|       1.0|\n",
      "|(30,[0,1,2,4,19,2...|    1|[9.19502172754844...|[0.36780086910193...|       1.0|\n",
      "|(30,[0,1,2,4,19,2...|    1|[8.90402733992878...|[0.35616109359715...|       1.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfpredictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29828"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvresult.filter(col(\"prediction\") == 0.0).count()\n",
    "#tvresult.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}